{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible analyzing tools / ML projects / Recommender System for reference\n",
    "# https://medium.com/data-scientists-playground/wide-deep%E6%A8%A1%E5%9E%8B-%E6%8E%A8%E8%96%A6%E7%B3%BB%E7%B5%B1-%E5%8E%9F%E7%90%86-8badacf777f3\n",
    "# https://github.com/tensorflow/models/tree/master/official/wide_deep\n",
    "# https://tensorflow.juejin.im/get_started/feature_columns.html\n",
    "# https://www.slideshare.net/JamesKirk58/boston-ml-architecting-recommender-systems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "#set chinese font\n",
    "from matplotlib.font_manager import FontProperties\n",
    "sn.set(font=['sans-serif'])\n",
    "sn.set_style(\"whitegrid\",{\"font.sans-serif\":['Microsoft JhengHei']})\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from _module_.dbtool import io, compute\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 會員瀏覽(by member_id & 料號) + 會員購買"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Established.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_id</th>\n",
       "      <th>p_no</th>\n",
       "      <th>p_name</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>date</th>\n",
       "      <th>sessionnumber</th>\n",
       "      <th>time</th>\n",
       "      <th>ndate</th>\n",
       "      <th>nsess</th>\n",
       "      <th>ntime</th>\n",
       "      <th>freq1</th>\n",
       "      <th>freq2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010</td>\n",
       "      <td>502400149502</td>\n",
       "      <td>吹風機/TESCOM 大風量負離子吹風機 TID192TW 白</td>\n",
       "      <td>生活家電</td>\n",
       "      <td>吹風機</td>\n",
       "      <td>TESCOM</td>\n",
       "      <td>[2019-07-01]</td>\n",
       "      <td>[27440359]</td>\n",
       "      <td>[2019-07-01 22:42:18.694000, 2019-07-01 22:45:...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.560894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100010</td>\n",
       "      <td>502401809532</td>\n",
       "      <td>吹風機/TESCOM TID292TW 大風量負離子吹風機 白</td>\n",
       "      <td>生活家電</td>\n",
       "      <td>吹風機</td>\n",
       "      <td>TESCOM</td>\n",
       "      <td>[2019-07-01]</td>\n",
       "      <td>[27440359]</td>\n",
       "      <td>[2019-07-01 22:43:07.958000, 2019-07-01 22:45:...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  member_id          p_no                           p_name level1 level2  \\\n",
       "0    100010  502400149502  吹風機/TESCOM 大風量負離子吹風機 TID192TW 白   生活家電    吹風機   \n",
       "1    100010  502401809532  吹風機/TESCOM TID292TW 大風量負離子吹風機 白   生活家電    吹風機   \n",
       "\n",
       "   level3          date sessionnumber  \\\n",
       "0  TESCOM  [2019-07-01]    [27440359]   \n",
       "1  TESCOM  [2019-07-01]    [27440359]   \n",
       "\n",
       "                                                time  ndate  nsess  ntime  \\\n",
       "0  [2019-07-01 22:42:18.694000, 2019-07-01 22:45:...      1      1      4   \n",
       "1  [2019-07-01 22:43:07.958000, 2019-07-01 22:45:...      1      1      2   \n",
       "\n",
       "   freq1      freq2  \n",
       "0    5.0  85.560894  \n",
       "1  116.0   0.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 瀏覽數據\n",
    "df_pno = io.read_table('select * from felixlin.\"Proj006_browse+purchase_browse2019_bypno\" limit 200000')\n",
    "\n",
    "df_pno['ndate'] = df_pno['date'].apply(lambda x: len(x))\n",
    "df_pno['nsess'] = df_pno['sessionnumber'].apply(lambda x: len(x))\n",
    "df_pno['ntime'] = df_pno['time'].apply(lambda x: len(x))\n",
    "\n",
    "def time_diff(x):\n",
    "    tmp = np.sort(x)\n",
    "    tmp = np.array([(tmp[i]-tmp[i-1]).seconds for i in np.arange(1,len(tmp))])\n",
    "    return([np.median(tmp), tmp.std()])\n",
    "\n",
    "df_pno[['freq1','freq2']] = df_pno['time'].apply(lambda x: pd.Series(time_diff(x)))\n",
    "df_pno.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Established.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_id</th>\n",
       "      <th>p_no</th>\n",
       "      <th>p_name</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>date</th>\n",
       "      <th>sessionnumber</th>\n",
       "      <th>time</th>\n",
       "      <th>ndate</th>\n",
       "      <th>nsess</th>\n",
       "      <th>ntime</th>\n",
       "      <th>freq1</th>\n",
       "      <th>freq2</th>\n",
       "      <th>eorder_no</th>\n",
       "      <th>buytime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010</td>\n",
       "      <td>502400149502</td>\n",
       "      <td>吹風機/TESCOM 大風量負離子吹風機 TID192TW 白</td>\n",
       "      <td>生活家電</td>\n",
       "      <td>吹風機</td>\n",
       "      <td>TESCOM</td>\n",
       "      <td>[2019-07-01]</td>\n",
       "      <td>[27440359]</td>\n",
       "      <td>[2019-07-01 22:42:18.694000, 2019-07-01 22:45:...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.560894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  member_id          p_no                           p_name level1 level2  \\\n",
       "0    100010  502400149502  吹風機/TESCOM 大風量負離子吹風機 TID192TW 白   生活家電    吹風機   \n",
       "\n",
       "   level3          date sessionnumber  \\\n",
       "0  TESCOM  [2019-07-01]    [27440359]   \n",
       "\n",
       "                                                time  ndate  nsess  ntime  \\\n",
       "0  [2019-07-01 22:42:18.694000, 2019-07-01 22:45:...      1      1      4   \n",
       "\n",
       "   freq1      freq2 eorder_no buytime  \n",
       "0    5.0  85.560894       NaN     NaT  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 購買數據 & 合併瀏覽\n",
    "df_pno2 = io.read_table('felixlin.\"Proj006_browse+purchase_purchase2019_bypno\"','std')\n",
    "\n",
    "df_merge = df_pno.merge(df_pno2[['member_id','p_no', 'eorder_no', 'time']].rename({'time':'buytime'}, axis=1), \n",
    "                        on=['member_id','p_no'], how='left')\n",
    "df_merge.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_no, level1, level2 都要有值\n",
    "df_merge = df_merge[df_merge.p_no.notnull()]\n",
    "df_merge = df_merge[df_merge.level2.notnull()]\n",
    "df_merge = df_merge[df_merge.level3.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加入品牌資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Established.\n",
      "Connection Established.\n"
     ]
    }
   ],
   "source": [
    "# 獨資料\n",
    "df_brand = io.read_table('felixlin.\"002product_brand_ec_v2\"','std')\n",
    "df_itemno = io.read_table('select item_no, brand from felixlin.\"002product_brand_v3\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理資料\n",
    "brand_dict = {df_brand.iloc[i][0]:df_brand.iloc[i][1] for i in np.arange(df_brand.shape[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_id</th>\n",
       "      <th>p_no</th>\n",
       "      <th>p_name</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>date</th>\n",
       "      <th>sessionnumber</th>\n",
       "      <th>time</th>\n",
       "      <th>ndate</th>\n",
       "      <th>nsess</th>\n",
       "      <th>ntime</th>\n",
       "      <th>freq1</th>\n",
       "      <th>freq2</th>\n",
       "      <th>eorder_no</th>\n",
       "      <th>buytime</th>\n",
       "      <th>buy</th>\n",
       "      <th>item_no_x</th>\n",
       "      <th>brand_x</th>\n",
       "      <th>item_no_y</th>\n",
       "      <th>brand_y</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010</td>\n",
       "      <td>502400149502</td>\n",
       "      <td>吹風機/TESCOM 大風量負離子吹風機 TID192TW 白</td>\n",
       "      <td>生活家電</td>\n",
       "      <td>吹風機</td>\n",
       "      <td>TESCOM</td>\n",
       "      <td>[2019-07-01]</td>\n",
       "      <td>[27440359]</td>\n",
       "      <td>[2019-07-01 22:42:18.694000, 2019-07-01 22:45:...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.560894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>502400149502</td>\n",
       "      <td>東元</td>\n",
       "      <td>502400149502</td>\n",
       "      <td>TESCOM</td>\n",
       "      <td>東元</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  member_id          p_no                           p_name level1 level2  \\\n",
       "0    100010  502400149502  吹風機/TESCOM 大風量負離子吹風機 TID192TW 白   生活家電    吹風機   \n",
       "\n",
       "   level3          date sessionnumber  \\\n",
       "0  TESCOM  [2019-07-01]    [27440359]   \n",
       "\n",
       "                                                time  ndate  nsess  ntime  \\\n",
       "0  [2019-07-01 22:42:18.694000, 2019-07-01 22:45:...      1      1      4   \n",
       "\n",
       "   freq1      freq2 eorder_no buytime  buy     item_no_x brand_x  \\\n",
       "0    5.0  85.560894       NaN     NaT    1  502400149502      東元   \n",
       "\n",
       "      item_no_y brand_y brand  \n",
       "0  502400149502  TESCOM    東元  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合併表格\n",
    "df_merge = df_merge.merge(df_itemno, left_on='p_no', right_on='item_no', how='left')\n",
    "df_merge = df_merge.drop('item_no',1)\n",
    "# 轉成乾淨的品牌\n",
    "df_merge['brand'] = df_merge['brand'].map(brand_dict)\n",
    "df_merge.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_pno, df_pno2, df_brand, df_itemno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorrec\n",
    "#<module 'tensorrec' from 'c:\\\\users\\\\017084\\\\appdata\\\\local\\\\continuum\\\\anaconda3\\\\envs\\\\work\\\\lib\\\\site-packages\\\\tensorrec\\\\__init__.py'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "from scipy import sparse\n",
    "import tensorrec\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將id做對應，產生dictionary\n",
    "def value_map(df, col):\n",
    "    uni = np.sort(df[col].fillna('NaN').unique())\n",
    "    return({uni[i]:i for i in np.arange(uni.shape[0])})\n",
    "\n",
    "value_map_reverse = lambda x: {value:key for key, value in x.items()}\n",
    "\n",
    "def append_value_map(old_dict, new_df, col):\n",
    "    max_index = max(old_dict.values())\n",
    "    uni = np.sort(new_df[col].unique())\n",
    "    uni = np.setdiff1d(uni, list(old_dict.keys()))\n",
    "    new_dict = old_dict.copy()\n",
    "    new_dict.update({uni[i]:(max_index+i+1) for i in np.arange(uni.shape[0])})\n",
    "    return(new_dict)\n",
    "\n",
    "# This method converts a list of (user, item, rating, time) to a sparse matrix\n",
    "def interactions_to_sparse(interactions, n_users, n_items):\n",
    "    users_column, items_column, buy_column  = zip(*interactions.values.tolist())\n",
    "    return(sparse.coo_matrix((buy_column, (users_column, items_column)),shape=(n_users, n_items)))\n",
    "\n",
    "# This method consumes item ranks for each user and prints out recall@10 train/test metrics\n",
    "def check_results(ranks, sparse_train2, sparse_test2, k=10):\n",
    "    train_recall_at_10 = tensorrec.eval.__recall_at_k(test_interactions=sparse_train2,predicted_ranks=ranks,k=k).mean()\n",
    "    test_recall_at_10 = tensorrec.eval.__recall_at_k(test_interactions=sparse_test2,predicted_ranks=ranks,k=k).mean()\n",
    "    print(\"Recall at {}: Train: {:.4f} Test: {:.4f}\".format(k,train_recall_at_10,test_recall_at_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整理會員和商品數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 數據清理\n",
    "df_merge['buy'] = df_merge.buytime.apply(lambda x: 1 if pd.isnull(x) else 2)\n",
    "df_use = df_merge[['member_id','p_no','buy']]\n",
    "\n",
    "# 要去掉為NULL的數據\n",
    "mmb_map= value_map(df_use, 'member_id')\n",
    "item_map= value_map(df_use, 'p_no')\n",
    "\n",
    "df_use['member_id'] = df_use['member_id'].map(mmb_map)\n",
    "df_use['p_no'] = df_use['p_no'].map(item_map)\n",
    "\n",
    "# unique的會員數和商品數\n",
    "n_users = df_use.member_id.nunique()\n",
    "n_items = df_use.p_no.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分成training 和 testing\n",
    "df_use = df_use.sample(frac=1)\n",
    "cutoff = int((df_use.shape[0])*0.7)\n",
    "train_ratings = df_use[:cutoff]\n",
    "test_ratings = df_use[cutoff:]\n",
    "\n",
    "# 轉成Sparse Matrix\n",
    "sparse_train = interactions_to_sparse(train_ratings, n_users, n_items)\n",
    "sparse_test = interactions_to_sparse(test_ratings, n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_use, train_ratings, test_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct indicator features for users and items\n",
    "user_indicator = sparse.identity(n_users)\n",
    "item_indicator = sparse.identity(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict_rank(model, ufeat, ifeat, bsize=1000, nrank=300):\n",
    "    length = ufeat.shape[0]\n",
    "    blen = int(length/bsize)+1 if length%bsize!=0 else int(length/bsize)\n",
    "    ufeat_tmp = ufeat.tocsr()\n",
    "    for i in np.arange(blen):\n",
    "        if i != blen-1:\n",
    "            rank_data = model.predict_rank(user_features=ufeat_tmp[(i*bsize):((i+1)*bsize),],item_features=ifeat)\n",
    "        else:\n",
    "            rank_data = model.predict_rank(user_features=ufeat_tmp[(i*bsize):,],item_features=ifeat)\n",
    "        rank_data = sparse.csr_matrix(rank_data*np.less(rank_data, (nrank + 1)))\n",
    "        arr = rank_data if i == 0 else sparse.vstack([arr, rank_data])\n",
    "    return(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_id</th>\n",
       "      <th>p_no</th>\n",
       "      <th>p_name</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>date</th>\n",
       "      <th>sessionnumber</th>\n",
       "      <th>time</th>\n",
       "      <th>ndate</th>\n",
       "      <th>nsess</th>\n",
       "      <th>ntime</th>\n",
       "      <th>freq1</th>\n",
       "      <th>freq2</th>\n",
       "      <th>eorder_no</th>\n",
       "      <th>buytime</th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010</td>\n",
       "      <td>502400149502</td>\n",
       "      <td>吹風機/TESCOM 大風量負離子吹風機 TID192TW 白</td>\n",
       "      <td>生活家電</td>\n",
       "      <td>吹風機</td>\n",
       "      <td>TESCOM</td>\n",
       "      <td>[2019-07-01]</td>\n",
       "      <td>[27440359]</td>\n",
       "      <td>[2019-07-01 22:42:18.694000, 2019-07-01 22:45:...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.560894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  member_id          p_no                           p_name level1 level2  \\\n",
       "0    100010  502400149502  吹風機/TESCOM 大風量負離子吹風機 TID192TW 白   生活家電    吹風機   \n",
       "\n",
       "   level3          date sessionnumber  \\\n",
       "0  TESCOM  [2019-07-01]    [27440359]   \n",
       "\n",
       "                                                time  ndate  nsess  ntime  \\\n",
       "0  [2019-07-01 22:42:18.694000, 2019-07-01 22:45:...      1      1      4   \n",
       "\n",
       "   freq1      freq2 eorder_no buytime  buy  \n",
       "0    5.0  85.560894       NaN     NaT    1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-Based Item Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 數據清理\n",
    "df_item = df_merge[['p_no', 'p_name','level1','level2','level3', 'brand']]\n",
    "\n",
    "level1_map= value_map(df_item, 'level1')\n",
    "level2_map= value_map(df_item, 'level2')\n",
    "level3_map= value_map(df_item, 'level3')\n",
    "brand_map = value_map(df_merge, 'brand')\n",
    "\n",
    "df_item['p_no'] = df_item['p_no'].map(item_map)\n",
    "df_item['level1'] = df_item['level1'].map(level1_map)\n",
    "df_item['level2'] = df_item['level2'].map(level2_map)\n",
    "df_item['level3'] = df_item['level3'].map(level3_map)\n",
    "df_item['brand'] = df_item['brand'].map(brand_map)\n",
    "\n",
    "item_tmp = df_item[['p_no','level1','level2','level3','brand']].drop_duplicates(['p_no','level1','level2','level3','brand']).sort_values(['p_no','level1','level2','level3','brand'])\n",
    "# 檢查p_no和level1,level2是否1->1\n",
    "# df_item[['p_no','level1','level2']].p_no.nunique()\n",
    "\n",
    "item_level1 = sparse.coo_matrix(pd.get_dummies(item_tmp['level1']))\n",
    "item_level2 = sparse.coo_matrix(pd.get_dummies(item_tmp['level2']))\n",
    "item_level3 = sparse.coo_matrix(pd.get_dummies(item_tmp['level3']))\n",
    "item_brand = sparse.coo_matrix(pd.get_dummies(item_tmp['brand']))\n",
    "item_levels = sparse.hstack([item_level1, item_level2, item_level3, item_brand])\n",
    "n_item = item_levels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_levels = sparse.hstack([item_level1, item_level2, item_level3])\n",
    "n_item = item_levels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加入會員 META DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Established.\n"
     ]
    }
   ],
   "source": [
    "df_mmb = io.read_table('felixlin.\"Proj006_browse+purchase_mmb_info\"','std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年齡層\n",
    "bins= [-999,0,20,30,40,50,60,120]\n",
    "labels = np.arange(len(bins)-1)\n",
    "df_mmb['age'] = df_mmb['age'].fillna(-1)\n",
    "df_mmb['age'] = pd.cut(df_mmb['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# 性別\n",
    "df_mmb['sex'] = df_mmb.sex.fillna('N')\n",
    "sex_map = value_map(df_mmb,'sex')\n",
    "df_mmb['sex'] = df_mmb['sex'].map(sex_map)\n",
    "\n",
    "# 註冊日\n",
    "bins= [0,180,360,720,10000]\n",
    "labels = np.arange(len(bins)-1)\n",
    "df_mmb['rdays'] = pd.cut(df_mmb['rdays'], bins=bins, labels=labels, right=False)\n",
    "if df_mmb.rdays.isnull().any():\n",
    "    df_mmb['rdays'] = df_mmb['rdays'].fillna(len(bins)-1)\n",
    "\n",
    "# 裝置\n",
    "df_mmb['os_type'] = df_mmb.os_type.fillna('z')\n",
    "os_map = value_map(df_mmb,'os_type')\n",
    "df_mmb['os_type'] = df_mmb['os_type'].map(os_map)\n",
    "\n",
    "# 地區\n",
    "dict_city={\"花蓮縣\":\"東部與外島地區\", \"宜蘭縣\":\"北部地區\", \"台東縣\":\"東部與外島地區\", \"南投縣\":\"中部地區\", \n",
    "           \"金門縣\":\"東部與外島地區\", \"嘉義縣\":\"南部地區\", \"基隆市\":\"北部地區\", \"彰化縣\":\"中部地區\", \n",
    "           \"台中市\":\"中部地區\", \"雲林縣\":\"南部地區\", \"高雄市\":\"南部地區\", \"桃園縣\":\"北部地區\", \n",
    "           \"新竹縣\":\"北部地區\", \"新竹市\":\"北部地區\", \"苗栗縣\":\"中部地區\", \"新北市\":\"北部地區\", \n",
    "           \"台北市\":\"北部地區\", \"連江縣\":\"東部與外島地區\", \"桃園市\":\"北部地區\", \"屏東縣\":\"南部地區\", \n",
    "           \"台南市\":\"南部地區\", \"嘉義市\":\"南部地區\", \"澎湖縣\":\"東部與外島地區\", \"未知\":\"未知\"}\n",
    "\n",
    "df_mmb['c_city'] = df_mmb.c_city.fillna('未知')\n",
    "df_mmb['c_city'] = df_mmb['c_city'].map(dict_city)\n",
    "city_map = value_map(df_mmb,'c_city')\n",
    "df_mmb['c_city'] = df_mmb['c_city'].map(city_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 members are not listed in member info.\n",
      "Already added to member info.\n"
     ]
    }
   ],
   "source": [
    "# 消失的會員，補上遺失資料\n",
    "expectmmb = set(df_merge.member_id.unique())\n",
    "getmmb = set(df_mmb[df_mmb.member_id.isin(df_merge.member_id)].member_id.unique())\n",
    "if len(getmmb)<len(expectmmb):\n",
    "    diff = expectmmb.difference(getmmb)\n",
    "    print('{} members are not listed in member info.\\nAlready added to member info.'.format(len(diff)))\n",
    "    df_mmb = pd.concat([df_mmb, pd.DataFrame([[i,0,2,4,3,2] for i in diff], columns=['member_id', 'age','sex','rdays','c_city','os_type'])],0)\n",
    "else:\n",
    "    print(\"All members are listed\")\n",
    "\n",
    "#df_mmb = pd.concat([df_mmb, pd.DataFrame([['1242148',0,2,0,3,2]], columns=['member_id', 'age','sex','rdays','c_city','os_type'])],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 會員資料的ID轉換成建模時的ID\n",
    "df_mmb2 = df_mmb[df_mmb.member_id.isin(df_merge.member_id)]\n",
    "df_mmb2['member_id'] = df_mmb2.member_id.map(mmb_map)\n",
    "\n",
    "# Create User Full Matrix\n",
    "df_mmb2 = df_mmb2.sort_values('member_id')\n",
    "user_meta = sparse.hstack([sparse.coo_matrix(pd.get_dummies(df_mmb2['age'])),\n",
    "                           sparse.coo_matrix(pd.get_dummies(df_mmb2['sex'])),\n",
    "                           sparse.coo_matrix(pd.get_dummies(df_mmb2['rdays'])),\n",
    "                           sparse.coo_matrix(pd.get_dummies(df_mmb2['os_type'])),\n",
    "                           sparse.coo_matrix(pd.get_dummies(df_mmb2['c_city']))\n",
    "                          ])\n",
    "# Use Hybrid Model\n",
    "item_full = sparse.hstack([item_indicator, item_levels])\n",
    "user_full = sparse.hstack([user_indicator, user_meta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pno_map_to_pname = df_merge[['p_no','p_name']].drop_duplicates(['p_no','p_name']).set_index('p_no').p_name.to_dict()\n",
    "item_map_reverse = value_map_reverse(item_map)\n",
    "mmb_map_reverse = value_map_reverse(mmb_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training collaborative filter\n"
     ]
    }
   ],
   "source": [
    "# Build a matrix factorization collaborative filter model\n",
    "cf_model = tensorrec.TensorRec(n_components=5)\n",
    "# Fit the collaborative filter model\n",
    "print(\"Training collaborative filter\")\n",
    "cf_model.fit(interactions=sparse_train,user_features=user_indicator,item_features=item_indicator, user_batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix factorization collaborative filter:\n",
      "Recall at 10: Train: 0.0006 Test: 0.0006\n"
     ]
    }
   ],
   "source": [
    "# Create sets of train/test interactions that are only ratings >= 4.0\n",
    "sparse_train2 = sparse_train.multiply(sparse_train >= 2.0)\n",
    "sparse_test2 = sparse_test.multiply(sparse_test >= 2.0)    \n",
    "\n",
    "# Check the results of the MF CF model\n",
    "print(\"Matrix factorization collaborative filter:\")\n",
    "predicted_ranks = batch_predict_rank(cf_model,user_indicator,item_indicator,2000)\n",
    "#predicted_ranks = cf_model.predict_rank(user_features=user_indicator,item_features=item_indicator)\n",
    "check_results(predicted_ranks,sparse_train2, sparse_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training collaborative filter with WMRB loss\n",
      "WMRB matrix factorization collaborative filter:\n"
     ]
    }
   ],
   "source": [
    "# Let's try a new loss function: WMRB\n",
    "print(\"Training collaborative filter with WMRB loss\")\n",
    "ranking_cf_model = tensorrec.TensorRec(n_components=5,loss_graph=tensorrec.loss_graphs.WMRBLossGraph())\n",
    "ranking_cf_model.fit(interactions=sparse_train,user_features=user_indicator,item_features=item_indicator,n_sampled_items=int(n_items * .01))\n",
    "# Check the results of the WMRB MF CF model\n",
    "print(\"WMRB matrix factorization collaborative filter:\")\n",
    "#predicted_ranks = ranking_cf_model.predict_rank(user_features=user_indicator,item_features=item_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMRB matrix factorization collaborative filter:\n",
      "Recall at 10: Train: 0.1118 Test: 0.0395\n"
     ]
    }
   ],
   "source": [
    "#### Try Batches\n",
    "print(\"WMRB matrix factorization collaborative filter:\")\n",
    "predicted_ranks = batch_predict_rank(ranking_cf_model,user_indicator,item_indicator,2000)\n",
    "# 看最後的分數\n",
    "check_results(predicted_ranks,sparse_train2, sparse_test2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training content-based recommender...\n"
     ]
    }
   ],
   "source": [
    "# Fit a content-based model using the genres as item features\n",
    "print(\"Training content-based recommender...\")\n",
    "content_model = tensorrec.TensorRec(n_components=n_item,item_repr_graph=tensorrec.representation_graphs.FeaturePassThroughRepresentationGraph(),\n",
    "                                    loss_graph=tensorrec.loss_graphs.WMRBLossGraph())\n",
    "content_model.fit(interactions=sparse_train,user_features=user_indicator,\n",
    "                  item_features=item_levels,n_sampled_items=int(n_items * .01),user_batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the results of the content-based model\n",
    "print(\"Content-based recommender:\")\n",
    "#predicted_ranks = content_model.predict_rank(user_features=user_indicator,item_features=item_levels)\n",
    "predicted_ranks = batch_predict_rank(content_model,user_indicator,item_levels,1000)\n",
    "check_results(predicted_ranks,sparse_train, sparse_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results(predicted_ranks,sparse_train, sparse_test, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try concatenating the genres on to the indicator features for a hybrid recommender system\n",
    "item_full = sparse.hstack([item_indicator, item_levels])\n",
    "print(\"Training hybrid recommender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = tensorrec.TensorRec(n_components=20,loss_graph=tensorrec.loss_graphs.WMRBLossGraph())\n",
    "hybrid_model.fit(interactions=sparse_train,user_features=user_indicator,\n",
    "                 item_features=item_full,n_sampled_items=int(n_items * .01),user_batch_size=500)\n",
    "print(\"Hybrid recommender:\")\n",
    "predicted_ranks = batch_predict_rank(hybrid_model, user_indicator,item_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results(predicted_ranks,sparse_train, sparse_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 看單一會員的推薦狀況"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull user 432's features out of the user features matrix and predict movie ranks for just that user\n",
    "mmbtest = 400\n",
    "u432_features = sparse.csr_matrix(user_indicator)[mmbtest]\n",
    "u432_rankings = hybrid_model.predict_rank(user_features=u432_features,item_features=item_full)[0]\n",
    "# Get internal IDs of User 432's top 10 recommendations\n",
    "# These are sorted by item ID, not by rank\n",
    "# This may contain items with which User 432 has already interacted\n",
    "u432_top_ten_recs = np.where(u432_rankings <= 30)[0]\n",
    "u432_top_ten_recs\n",
    "\n",
    "print(\"User {} recommendations:\".format(mmbtest))\n",
    "for m in u432_top_ten_recs:\n",
    "    print('{}\\t{}'.format(item_map_reverse[m], pno_map_to_pname[item_map_reverse[m]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge[df_merge.member_id==mmb_map_reverse[mmbtest]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Model w/ 會員數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training hybrid recommender\")\n",
    "hybrid_model = tensorrec.TensorRec(n_components=5,loss_graph=tensorrec.loss_graphs.WMRBLossGraph())\n",
    "hybrid_model.fit(interactions=sparse_train,user_features=user_full,\n",
    "                 item_features=item_full,n_sampled_items=int(n_items * .01), user_batch_size=1000)\n",
    "\n",
    "#print(\"Hybrid recommender:\")\n",
    "predicted_ranks = batch_predict_rank(hybrid_model, user_full,item_full)\n",
    "check_results(predicted_ranks,sparse_train, sparse_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results(predicted_ranks,sparse_train, sparse_test, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training hybrid recommender\")\n",
    "hybrid_model = tensorrec.TensorRec(n_components=9,loss_graph=tensorrec.loss_graphs.WMRBLossGraph())\n",
    "hybrid_model.fit(interactions=sparse_train,user_features=user_full,\n",
    "                 item_features=item_full,n_sampled_items=int(n_items * .01), user_batch_size=1000)\n",
    "\n",
    "#print(\"Hybrid recommender:\")\n",
    "predicted_ranks = batch_predict_rank(hybrid_model, user_full,item_full)\n",
    "check_results(predicted_ranks,sparse_train, sparse_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results(predicted_ranks,sparse_train, sparse_test, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用tensorrec內建的NN ReLU作為graph representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorrec.representation_graphs import (ReLURepresentationGraph, AbstractKerasRepresentationGraph, \n",
    "    LinearRepresentationGraph, NormalizedLinearRepresentationGraph, AbstractRepresentationGraph)\n",
    "from tensorrec.prediction_graphs import CosineSimilarityPredictionGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm1 = compute.timerec()\n",
    "#tm2 = compute.timerec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Hybrid Model\n",
    "tm1.start()\n",
    "print(\"Training hybrid neural network recommender\")\n",
    "hybrid_model1 = tensorrec.TensorRec(n_components=10,\n",
    "                                   loss_graph=tensorrec.loss_graphs.BalancedWMRBLossGraph(),\n",
    "                                   user_repr_graph = LinearRepresentationGraph(),\n",
    "                                   item_repr_graph = LinearRepresentationGraph()#,\n",
    "                                   #attention_graph = AbstractRepresentationGraph()\n",
    "                                   )\n",
    "hybrid_model1.fit(interactions=sparse_train,user_features=user_full,\n",
    "                 item_features=item_full,n_sampled_items=int(n_items * .01), user_batch_size=1000)\n",
    "tm1.end()\n",
    "tm1.delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hybrid recommender:\")\n",
    "predicted_ranks = batch_predict_rank(hybrid_model1, user_full,item_full, bsize=1000)\n",
    "check_results(predicted_ranks,sparse_train, sparse_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results(predicted_ranks,sparse_train, sparse_test, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1 = hybrid_model1.predict_similar_items(item_full, np.arange(1,100), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sim1)):\n",
    "    print('item_id: {}\\t{}\\nSimilar items:'.format(i, pno_map_to_pname[item_map_reverse[i]]))\n",
    "    for j in sim1[i]:\n",
    "        print(pno_map_to_pname[item_map_reverse[j[0]]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
